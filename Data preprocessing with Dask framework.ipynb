{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184cba15",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abdfe68",
   "metadata": {},
   "source": [
    "###### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3aa0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear algebra\n",
    "import numpy as np\n",
    "\n",
    "#working with data in table structers\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# data visualization\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# working with files\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# to off warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# data preprocessing\n",
    "from itertools import product\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "027c785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data path to sys.path \n",
    "clean_data_path = \"C:\\\\Repository\\\\DS-Intership-data\\\\clean_data\\\\\"\n",
    "sys.path.append(clean_data_path)\n",
    "\n",
    "# initiate dict for data\n",
    "to_read_clean_data = {}\n",
    "\n",
    "# fill to_read\n",
    "for dir_name, _, files in os.walk(clean_data_path):\n",
    "    for file in files:\n",
    "        to_read_clean_data[file] = dir_name + file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba3406cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items.csv': 'C:\\\\Repository\\\\DS-Intership-data\\\\clean_data\\\\items.csv',\n",
       " 'item_categories.csv': 'C:\\\\Repository\\\\DS-Intership-data\\\\clean_data\\\\item_categories.csv',\n",
       " 'sales_train.csv': 'C:\\\\Repository\\\\DS-Intership-data\\\\clean_data\\\\sales_train.csv',\n",
       " 'sample_submission.csv': 'C:\\\\Repository\\\\DS-Intership-data\\\\clean_data\\\\sample_submission.csv',\n",
       " 'shops.csv': 'C:\\\\Repository\\\\DS-Intership-data\\\\clean_data\\\\shops.csv',\n",
       " 'test.csv': 'C:\\\\Repository\\\\DS-Intership-data\\\\clean_data\\\\test.csv'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to_read\n",
    "to_read_clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ad96b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 969 ms\n",
      "Wall time: 1.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = {}\n",
    "# read data\n",
    "for file, path in to_read_clean_data.items():\n",
    "    data[file.split('.')[0]] = dd.read_csv(os.path.join(os.path.dirname(path), file)).set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb6ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data path to sys.path \n",
    "cluster_data_path = \"C:\\\\Repository\\\\DS-Intership-data\\\\cluster_data\\\\\"\n",
    "sys.path.append(cluster_data_path)\n",
    "\n",
    "# initiate dict for data\n",
    "to_read_cluster_data = {}\n",
    "\n",
    "# fill to_read\n",
    "for dir_name, _, files in os.walk(cluster_data_path):\n",
    "    for file in files:\n",
    "        to_read_cluster_data[file] = dir_name + file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "749d603b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item_category_clusters.csv': 'C:\\\\Repository\\\\DS-Intership-data\\\\cluster_data\\\\item_category_clusters.csv',\n",
       " 'item_price_clusters.csv': 'C:\\\\Repository\\\\DS-Intership-data\\\\cluster_data\\\\item_price_clusters.csv',\n",
       " 'shop_clusters.csv': 'C:\\\\Repository\\\\DS-Intership-data\\\\cluster_data\\\\shop_clusters.csv',\n",
       " 'subtype_clusters.csv': 'C:\\\\Repository\\\\DS-Intership-data\\\\cluster_data\\\\subtype_clusters.csv',\n",
       " 'type_code_clusters.csv': 'C:\\\\Repository\\\\DS-Intership-data\\\\cluster_data\\\\type_code_clusters.csv'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to_read\n",
    "to_read_cluster_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420f2344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.97 s\n",
      "Wall time: 5.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cluster_data = {}\n",
    "# read data\n",
    "for file, path in to_read_cluster_data.items():\n",
    "    cluster_data[file.split('.')[0]] = dd.read_csv(os.path.join(os.path.dirname(path), file), dtype='object').\\\n",
    "                                                                                            set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d61c3",
   "metadata": {},
   "source": [
    "##### Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a381ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 32s\n",
      "Wall time: 2min 2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=33</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int32</td>\n",
       "      <td>int32</td>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: sort_values, 8 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               date_block_num shop_id item_id\n",
       "npartitions=33                               \n",
       "                        int32   int32   int32\n",
       "                          ...     ...     ...\n",
       "...                       ...     ...     ...\n",
       "                          ...     ...     ...\n",
       "                          ...     ...     ...\n",
       "Dask Name: sort_values, 8 graph layers"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# combinate month, shop and item in order of increasing month\n",
    "pretrained_data  = []\n",
    "cols  = [\"date_block_num\", \"shop_id\", \"item_id\"]\n",
    "for i in data['sales_train'].date_block_num.unique():\n",
    "    sales = data['sales_train'][data['sales_train'].date_block_num == i]\n",
    "    pretrained_data.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique()))))\n",
    "\n",
    "pretrained_data = dd.from_pandas(data=pd.DataFrame(np.vstack(pretrained_data), columns = cols), npartitions=100)#.reset_index()\n",
    "pretrained_data.sort_values(cols, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "317ae0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 47 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  shop_id  item_id\n",
       "0               0       59    22154\n",
       "1               0       59     2552\n",
       "2               0       59     2554\n",
       "3               0       59     2555\n",
       "4               0       59     2564"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pretrained_data.compute().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb4df505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 26 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Delayed('int-11292269-1b32-4274-a36b-c5c487dd07c5'), 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# merge datasets for data preprocessing\n",
    "pretrained_data = dd.merge(pretrained_data, data['shops'], on = [\"shop_id\"], how = \"left\" )\n",
    "pretrained_data = dd.merge(pretrained_data, data['items'], on = [\"item_id\"], how = \"left\")\n",
    "pretrained_data = dd.merge(pretrained_data, data['item_categories'], on = [\"item_category_id\"], how = \"left\" )\n",
    "pretrained_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8202b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.33 s\n",
      "Wall time: 4.78 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_name</th>\n",
       "      <th>city</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>Ярославль ТЦ \"Альтаир\"</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>ЯВЛЕНИЕ 2012 (BD)</td>\n",
       "      <td>37</td>\n",
       "      <td>Кино - Blu-Ray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2552</td>\n",
       "      <td>Ярославль ТЦ \"Альтаир\"</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>DEEP PURPLE  The House Of Blue Light  LP</td>\n",
       "      <td>58</td>\n",
       "      <td>Музыка - Винил</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2554</td>\n",
       "      <td>Ярославль ТЦ \"Альтаир\"</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>DEEP PURPLE  Who Do You Think We Are  LP</td>\n",
       "      <td>58</td>\n",
       "      <td>Музыка - Винил</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2555</td>\n",
       "      <td>Ярославль ТЦ \"Альтаир\"</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>DEEP PURPLE 30 Very Best Of 2CD (Фирм.)</td>\n",
       "      <td>56</td>\n",
       "      <td>Музыка - CD фирменного производства</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2564</td>\n",
       "      <td>Ярославль ТЦ \"Альтаир\"</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>DEEP PURPLE Perihelion: Live In Concert DVD (К...</td>\n",
       "      <td>59</td>\n",
       "      <td>Музыка - Музыкальное видео</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  shop_id  item_id               shop_name       city  \\\n",
       "0               0       59    22154  Ярославль ТЦ \"Альтаир\"  Ярославль   \n",
       "1               0       59     2552  Ярославль ТЦ \"Альтаир\"  Ярославль   \n",
       "2               0       59     2554  Ярославль ТЦ \"Альтаир\"  Ярославль   \n",
       "3               0       59     2555  Ярославль ТЦ \"Альтаир\"  Ярославль   \n",
       "4               0       59     2564  Ярославль ТЦ \"Альтаир\"  Ярославль   \n",
       "\n",
       "                                           item_name  item_category_id  \\\n",
       "0                                  ЯВЛЕНИЕ 2012 (BD)                37   \n",
       "1           DEEP PURPLE  The House Of Blue Light  LP                58   \n",
       "2           DEEP PURPLE  Who Do You Think We Are  LP                58   \n",
       "3            DEEP PURPLE 30 Very Best Of 2CD (Фирм.)                56   \n",
       "4  DEEP PURPLE Perihelion: Live In Concert DVD (К...                59   \n",
       "\n",
       "                    item_category_name  \n",
       "0                       Кино - Blu-Ray  \n",
       "1                       Музыка - Винил  \n",
       "2                       Музыка - Винил  \n",
       "3  Музыка - CD фирменного производства  \n",
       "4           Музыка - Музыкальное видео  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pretrained_data.compute().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e1beeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 27.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Delayed('int-f0a62309-b779-4763-89a9-465595a7844d'), 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# add count of sold items per month\n",
    "group = data['sales_train'].groupby([\"date_block_num\", \"shop_id\", \"item_id\"]).agg({\"item_cnt_day\": [\"sum\"]})\n",
    "group.columns = [\"item_cnt_month\"]\n",
    "#group.reset_index(inplace = True)\n",
    "pretrained_data = dd.merge(pretrained_data, group, on = cols, how = \"left\")\n",
    "pretrained_data[\"item_cnt_month\"] = pretrained_data[\"item_cnt_month\"].fillna(0)\n",
    "pretrained_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef7254c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 59.5 s\n",
      "Wall time: 15.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_name</th>\n",
       "      <th>city</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_category_name</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>Ярославль ТЦ \"Альтаир\"</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>ЯВЛЕНИЕ 2012 (BD)</td>\n",
       "      <td>37</td>\n",
       "      <td>Кино - Blu-Ray</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2552</td>\n",
       "      <td>Ярославль ТЦ \"Альтаир\"</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>DEEP PURPLE  The House Of Blue Light  LP</td>\n",
       "      <td>58</td>\n",
       "      <td>Музыка - Винил</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2554</td>\n",
       "      <td>Ярославль ТЦ \"Альтаир\"</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>DEEP PURPLE  Who Do You Think We Are  LP</td>\n",
       "      <td>58</td>\n",
       "      <td>Музыка - Винил</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2555</td>\n",
       "      <td>Ярославль ТЦ \"Альтаир\"</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>DEEP PURPLE 30 Very Best Of 2CD (Фирм.)</td>\n",
       "      <td>56</td>\n",
       "      <td>Музыка - CD фирменного производства</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2564</td>\n",
       "      <td>Ярославль ТЦ \"Альтаир\"</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>DEEP PURPLE Perihelion: Live In Concert DVD (К...</td>\n",
       "      <td>59</td>\n",
       "      <td>Музыка - Музыкальное видео</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  shop_id  item_id               shop_name       city  \\\n",
       "0               0       59    22154  Ярославль ТЦ \"Альтаир\"  Ярославль   \n",
       "1               0       59     2552  Ярославль ТЦ \"Альтаир\"  Ярославль   \n",
       "2               0       59     2554  Ярославль ТЦ \"Альтаир\"  Ярославль   \n",
       "3               0       59     2555  Ярославль ТЦ \"Альтаир\"  Ярославль   \n",
       "4               0       59     2564  Ярославль ТЦ \"Альтаир\"  Ярославль   \n",
       "\n",
       "                                           item_name  item_category_id  \\\n",
       "0                                  ЯВЛЕНИЕ 2012 (BD)                37   \n",
       "1           DEEP PURPLE  The House Of Blue Light  LP                58   \n",
       "2           DEEP PURPLE  Who Do You Think We Are  LP                58   \n",
       "3            DEEP PURPLE 30 Very Best Of 2CD (Фирм.)                56   \n",
       "4  DEEP PURPLE Perihelion: Live In Concert DVD (К...                59   \n",
       "\n",
       "                    item_category_name  item_cnt_month  \n",
       "0                       Кино - Blu-Ray            1.00  \n",
       "1                       Музыка - Винил            0.00  \n",
       "2                       Музыка - Винил            0.00  \n",
       "3  Музыка - CD фирменного производства            0.00  \n",
       "4           Музыка - Музыкальное видео            0.00  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pretrained_data.compute().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4fe3d4",
   "metadata": {},
   "source": [
    "###### Add clusters features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2b094ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for df_name, df in cluster_data.items():\n",
    "#    for col in df.columns:\n",
    "#        df[col] = dd.to_numeric(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92f93a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# categories clusterization\n",
    "#pretrained_data = dd.merge(pretrained_data, cluster_data['item_category_clusters'], on='item_category_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e45844e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#pretrained_data.compute().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7ec62b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# price clusterization\n",
    "#pretrained_data = dd.merge(pretrained_data, cluster_data['item_price_clusters'], on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf72c85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#pretrained_data.compute().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc2b0d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# price clusterization\n",
    "#pretrained_data = dd.merge(pretrained_data, cluster_data['item_price_clusters'], on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "304db4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#pretrained_data.compute().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a95e3",
   "metadata": {},
   "source": [
    "###### Substruct some categories from string data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a522d894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 16 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Delayed('int-237ab908-b7eb-4033-b28b-ff851659784e'), 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# item categories data\n",
    "pretrained_data[\"type_code\"] = pretrained_data.item_category_name.apply(lambda x: x.split(\" \")[0]).astype(str)\n",
    "#pretrained_data.type_code = LabelEncoder().fit_transform(pretrained_data.type_code)\n",
    "pretrained_data[\"split\"] = pretrained_data.item_category_name.apply(lambda x: x.split(\"-\"))\n",
    "pretrained_data[\"subtype\"] = pretrained_data.split.apply(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "#pretrained_data[\"subtype_code\"] = LabelEncoder().fit_transform(pretrained_data[\"subtype\"])\n",
    "pretrained_data = pretrained_data.drop(columns=['item_category_name', 'split', 'subtype'])\n",
    "pretrained_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f95776f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 8s\n",
      "Wall time: 33.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_name</th>\n",
       "      <th>city</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>type_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>Ярославль ТЦ \"Альтаир\"</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>ЯВЛЕНИЕ 2012 (BD)</td>\n",
       "      <td>37</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Кино</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2552</td>\n",
       "      <td>Ярославль ТЦ \"Альтаир\"</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>DEEP PURPLE  The House Of Blue Light  LP</td>\n",
       "      <td>58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Музыка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2554</td>\n",
       "      <td>Ярославль ТЦ \"Альтаир\"</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>DEEP PURPLE  Who Do You Think We Are  LP</td>\n",
       "      <td>58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Музыка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2555</td>\n",
       "      <td>Ярославль ТЦ \"Альтаир\"</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>DEEP PURPLE 30 Very Best Of 2CD (Фирм.)</td>\n",
       "      <td>56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Музыка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2564</td>\n",
       "      <td>Ярославль ТЦ \"Альтаир\"</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>DEEP PURPLE Perihelion: Live In Concert DVD (К...</td>\n",
       "      <td>59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Музыка</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  shop_id  item_id               shop_name       city  \\\n",
       "0               0       59    22154  Ярославль ТЦ \"Альтаир\"  Ярославль   \n",
       "1               0       59     2552  Ярославль ТЦ \"Альтаир\"  Ярославль   \n",
       "2               0       59     2554  Ярославль ТЦ \"Альтаир\"  Ярославль   \n",
       "3               0       59     2555  Ярославль ТЦ \"Альтаир\"  Ярославль   \n",
       "4               0       59     2564  Ярославль ТЦ \"Альтаир\"  Ярославль   \n",
       "\n",
       "                                           item_name  item_category_id  \\\n",
       "0                                  ЯВЛЕНИЕ 2012 (BD)                37   \n",
       "1           DEEP PURPLE  The House Of Blue Light  LP                58   \n",
       "2           DEEP PURPLE  Who Do You Think We Are  LP                58   \n",
       "3            DEEP PURPLE 30 Very Best Of 2CD (Фирм.)                56   \n",
       "4  DEEP PURPLE Perihelion: Live In Concert DVD (К...                59   \n",
       "\n",
       "   item_cnt_month type_code  \n",
       "0            1.00      Кино  \n",
       "1            0.00    Музыка  \n",
       "2            0.00    Музыка  \n",
       "3            0.00    Музыка  \n",
       "4            0.00    Музыка  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pretrained_data.compute().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87e9fcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 12 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Delayed('int-f4000768-c54a-42bb-aa10-d3d7690f33b9'), 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# shops data\n",
    "pretrained_data[\"shop_city\"] = pretrained_data.shop_name.str.split(\" \").map(lambda x: x[0])\n",
    "pretrained_data[\"shop_category\"] = pretrained_data.shop_name.str.split(\" \").map(lambda x: x[1])\n",
    "#pretrained_data[\"shop_category\"] = LabelEncoder().fit_transform(pretrained_data.shop_category)\n",
    "#pretrained_data[\"shop_city\"] = LabelEncoder().fit_transform(pretrained_data.shop_city)\n",
    "pretrained_data = pretrained_data.drop(columns=['shop_name', 'city'])\n",
    "pretrained_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96781ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 28s\n",
      "Wall time: 1min 4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>type_code</th>\n",
       "      <th>shop_city</th>\n",
       "      <th>shop_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>ЯВЛЕНИЕ 2012 (BD)</td>\n",
       "      <td>37</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Кино</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>ТЦ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2552</td>\n",
       "      <td>DEEP PURPLE  The House Of Blue Light  LP</td>\n",
       "      <td>58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Музыка</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>ТЦ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2554</td>\n",
       "      <td>DEEP PURPLE  Who Do You Think We Are  LP</td>\n",
       "      <td>58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Музыка</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>ТЦ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2555</td>\n",
       "      <td>DEEP PURPLE 30 Very Best Of 2CD (Фирм.)</td>\n",
       "      <td>56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Музыка</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>ТЦ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2564</td>\n",
       "      <td>DEEP PURPLE Perihelion: Live In Concert DVD (К...</td>\n",
       "      <td>59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Музыка</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>ТЦ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  shop_id  item_id  \\\n",
       "0               0       59    22154   \n",
       "1               0       59     2552   \n",
       "2               0       59     2554   \n",
       "3               0       59     2555   \n",
       "4               0       59     2564   \n",
       "\n",
       "                                           item_name  item_category_id  \\\n",
       "0                                  ЯВЛЕНИЕ 2012 (BD)                37   \n",
       "1           DEEP PURPLE  The House Of Blue Light  LP                58   \n",
       "2           DEEP PURPLE  Who Do You Think We Are  LP                58   \n",
       "3            DEEP PURPLE 30 Very Best Of 2CD (Фирм.)                56   \n",
       "4  DEEP PURPLE Perihelion: Live In Concert DVD (К...                59   \n",
       "\n",
       "   item_cnt_month type_code  shop_city shop_category  \n",
       "0            1.00      Кино  Ярославль            ТЦ  \n",
       "1            0.00    Музыка  Ярославль            ТЦ  \n",
       "2            0.00    Музыка  Ярославль            ТЦ  \n",
       "3            0.00    Музыка  Ярославль            ТЦ  \n",
       "4            0.00    Музыка  Ярославль            ТЦ  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pretrained_data.compute().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c9532b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 33 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Delayed('int-7f6ced97-913d-436b-8fea-704b2c6d36db'), 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# item data\n",
    "pretrained_data[\"name1\"], pretrained_data[\"name2\"] = pretrained_data.item_name.str.split('[', n=1).str[0], pretrained_data.item_name.str.split('[', n=1).str[1]\n",
    "pretrained_data[\"name1\"], pretrained_data[\"name3\"] = pretrained_data.item_name.str.split('(', n=1).str[0], pretrained_data.item_name.str.split('(', n=1).str[1]\n",
    "\n",
    "# replace special characters and turn to lower case\n",
    "pretrained_data[\"name2\"] = pretrained_data.name2.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\n",
    "pretrained_data[\"name3\"] = pretrained_data.name3.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower()\n",
    "\n",
    "pretrained_data = pretrained_data.fillna('0')\n",
    "\n",
    "#pretrained_data.name2 = LabelEncoder().fit_transform(pretrained_data.name2)\n",
    "#pretrained_data.name3 = LabelEncoder().fit_transform(pretrained_data.name3)\n",
    "\n",
    "pretrained_data = pretrained_data.drop(columns=['name1', 'item_name']) \n",
    "pretrained_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddd0f9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 47s\n",
      "Wall time: 1min 36s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>type_code</th>\n",
       "      <th>shop_city</th>\n",
       "      <th>shop_category</th>\n",
       "      <th>name2</th>\n",
       "      <th>name3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>37</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Кино</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>ТЦ</td>\n",
       "      <td>0</td>\n",
       "      <td>bd)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2552</td>\n",
       "      <td>58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Музыка</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>ТЦ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2554</td>\n",
       "      <td>58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Музыка</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>ТЦ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2555</td>\n",
       "      <td>56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Музыка</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>ТЦ</td>\n",
       "      <td>0</td>\n",
       "      <td>фирм.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2564</td>\n",
       "      <td>59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Музыка</td>\n",
       "      <td>Ярославль</td>\n",
       "      <td>ТЦ</td>\n",
       "      <td>0</td>\n",
       "      <td>кир.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  shop_id  item_id  item_category_id  item_cnt_month  \\\n",
       "0               0       59    22154                37            1.00   \n",
       "1               0       59     2552                58            0.00   \n",
       "2               0       59     2554                58            0.00   \n",
       "3               0       59     2555                56            0.00   \n",
       "4               0       59     2564                59            0.00   \n",
       "\n",
       "  type_code  shop_city shop_category name2   name3  \n",
       "0      Кино  Ярославль            ТЦ     0     bd)  \n",
       "1    Музыка  Ярославль            ТЦ     0       0  \n",
       "2    Музыка  Ярославль            ТЦ     0       0  \n",
       "3    Музыка  Ярославль            ТЦ     0  фирм.)  \n",
       "4    Музыка  Ярославль            ТЦ     0   кир.)  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pretrained_data.compute().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976ca3ef",
   "metadata": {},
   "source": [
    "###### Timeseries feature extration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5cbefe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lag_feature(df, lags, col):\n",
    "    tmp = df[['date_block_num', 'shop_id', 'item_id', col]]\n",
    "    for i in lags:\n",
    "        shifted = tmp.copy()\n",
    "        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n",
    "        shifted['date_block_num'] += i\n",
    "        df = dd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df33d7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 158 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# item count per month lag\n",
    "pretrained_data = extract_lag_feature(pretrained_data, [1], 'item_cnt_month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e8b335e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ignoring exception in ensure_cleanup_on_exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\shuffle.py\", line 930, in ensure_cleanup_on_exception\n",
      "    yield\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\shuffle.py\", line 945, in shuffle_group_3\n",
      "    p.append(d, fsync=True)\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\encode.py\", line 23, in append\n",
      "    data = valmap(self.encode, data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\toolz\\dicttoolz.py\", line 85, in valmap\n",
      "    rv.update(zip(d.keys(), map(func, d.values())))\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\pandas.py\", line 180, in serialize\n",
      "    col_header, col_bytes = index_to_header_bytes(df.columns)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\pandas.py\", line 113, in index_to_header_bytes\n",
      "    header = (type(ind), ind._get_attributes_dict(), values.dtype, cat)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Index' object has no attribute '_get_attributes_dict'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\shuffle.py\", line 935, in ensure_cleanup_on_exception\n",
      "    p.drop()\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\encode.py\", line 39, in drop\n",
      "    return self.partd.drop()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\buffer.py\", line 78, in drop\n",
      "    self.slow.drop()\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\file.py\", line 97, in drop\n",
      "    os.mkdir(self.path)\n",
      "FileExistsError: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\maxim\\\\AppData\\\\Local\\\\Temp\\\\tmpehi1a25_.partd'\n",
      "ignoring exception in ensure_cleanup_on_exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\shuffle.py\", line 930, in ensure_cleanup_on_exception\n",
      "    yield\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\shuffle.py\", line 945, in shuffle_group_3\n",
      "    p.append(d, fsync=True)\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\encode.py\", line 23, in append\n",
      "    data = valmap(self.encode, data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\toolz\\dicttoolz.py\", line 85, in valmap\n",
      "    rv.update(zip(d.keys(), map(func, d.values())))\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\pandas.py\", line 180, in serialize\n",
      "    col_header, col_bytes = index_to_header_bytes(df.columns)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\pandas.py\", line 113, in index_to_header_bytes\n",
      "    header = (type(ind), ind._get_attributes_dict(), values.dtype, cat)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Index' object has no attribute '_get_attributes_dict'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\shuffle.py\", line 935, in ensure_cleanup_on_exception\n",
      "    p.drop()\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\encode.py\", line 39, in drop\n",
      "    return self.partd.drop()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\buffer.py\", line 78, in drop\n",
      "    self.slow.drop()\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\file.py\", line 95, in drop\n",
      "    shutil.rmtree(self.path)\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\shutil.py\", line 759, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\shutil.py\", line 603, in _rmtree_unsafe\n",
      "    onerror(os.scandir, path, sys.exc_info())\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\shutil.py\", line 600, in _rmtree_unsafe\n",
      "    with os.scandir(path) as scandir_it:\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\maxim\\\\AppData\\\\Local\\\\Temp\\\\tmpehi1a25_.partd'\n",
      "ignoring exception in ensure_cleanup_on_exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\shuffle.py\", line 930, in ensure_cleanup_on_exception\n",
      "    yield\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\shuffle.py\", line 945, in shuffle_group_3\n",
      "    p.append(d, fsync=True)\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\encode.py\", line 23, in append\n",
      "    data = valmap(self.encode, data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\toolz\\dicttoolz.py\", line 85, in valmap\n",
      "    rv.update(zip(d.keys(), map(func, d.values())))\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\pandas.py\", line 180, in serialize\n",
      "    col_header, col_bytes = index_to_header_bytes(df.columns)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\pandas.py\", line 113, in index_to_header_bytes\n",
      "    header = (type(ind), ind._get_attributes_dict(), values.dtype, cat)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Index' object has no attribute '_get_attributes_dict'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\shuffle.py\", line 935, in ensure_cleanup_on_exception\n",
      "    p.drop()\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\encode.py\", line 39, in drop\n",
      "    return self.partd.drop()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\buffer.py\", line 78, in drop\n",
      "    self.slow.drop()\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\file.py\", line 97, in drop\n",
      "    os.mkdir(self.path)\n",
      "FileExistsError: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\maxim\\\\AppData\\\\Local\\\\Temp\\\\tmpehi1a25_.partd'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Index' object has no attribute '_get_attributes_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m<timed eval>:1\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\base.py:310\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    287\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m compute(\u001b[38;5;28mself\u001b[39m, traverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\base.py:595\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    592\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[0;32m    593\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m--> 595\u001b[0m results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[0;32m     87\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[1;32m---> 89\u001b[0m results \u001b[38;5;241m=\u001b[39m get_async(\n\u001b[0;32m     90\u001b[0m     pool\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[0;32m     91\u001b[0m     pool\u001b[38;5;241m.\u001b[39m_max_workers,\n\u001b[0;32m     92\u001b[0m     dsk,\n\u001b[0;32m     93\u001b[0m     keys,\n\u001b[0;32m     94\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m     95\u001b[0m     get_id\u001b[38;5;241m=\u001b[39m_thread_get_id,\n\u001b[0;32m     96\u001b[0m     pack_exception\u001b[38;5;241m=\u001b[39mpack_exception,\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m         _execute_task(task, data)  \u001b[38;5;66;03m# Re-execute locally\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 511\u001b[0m         raise_exception(exc, tb)\n\u001b[0;32m    512\u001b[0m res, worker_id \u001b[38;5;241m=\u001b[39m loads(res_info)\n\u001b[0;32m    513\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m][key] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(exc, tb)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 319\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[1;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     task, data \u001b[38;5;241m=\u001b[39m loads(task_info)\n\u001b[1;32m--> 224\u001b[0m     result \u001b[38;5;241m=\u001b[39m _execute_task(task, data)\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m get_id()\n\u001b[0;32m    226\u001b[0m     result \u001b[38;5;241m=\u001b[39m dumps((result, \u001b[38;5;28mid\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\core.py:121\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    117\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m(_execute_task(a, cache) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args))\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\shuffle.py:945\u001b[0m, in \u001b[0;36mshuffle_group_3\u001b[1;34m(df, col, npartitions, p)\u001b[0m\n\u001b[0;32m    943\u001b[0m g \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(col)\n\u001b[0;32m    944\u001b[0m d \u001b[38;5;241m=\u001b[39m {i: g\u001b[38;5;241m.\u001b[39mget_group(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m g\u001b[38;5;241m.\u001b[39mgroups}\n\u001b[1;32m--> 945\u001b[0m p\u001b[38;5;241m.\u001b[39mappend(d, fsync\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\partd\\encode.py:23\u001b[0m, in \u001b[0;36mEncode.append\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mappend\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 23\u001b[0m     data \u001b[38;5;241m=\u001b[39m valmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode, data)\n\u001b[0;32m     24\u001b[0m     data \u001b[38;5;241m=\u001b[39m valmap(frame, data)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartd\u001b[38;5;241m.\u001b[39mappend(data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\toolz\\dicttoolz.py:85\u001b[0m, in \u001b[0;36mvalmap\u001b[1;34m(func, d, factory)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Apply function to values of dictionary\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m>>> bills = {\"Alice\": [20, 15, 30], \"Bob\": [10, 35]}\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    itemmap\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m rv \u001b[38;5;241m=\u001b[39m factory()\n\u001b[1;32m---> 85\u001b[0m rv\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mzip\u001b[39m(d\u001b[38;5;241m.\u001b[39mkeys(), \u001b[38;5;28mmap\u001b[39m(func, d\u001b[38;5;241m.\u001b[39mvalues())))\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rv\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\partd\\pandas.py:180\u001b[0m, in \u001b[0;36mserialize\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mserialize\u001b[39m(df):\n\u001b[0;32m    176\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Serialize and compress a Pandas DataFrame\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    Uses Pandas blocks, snappy, and blosc to deconstruct an array into bytes\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     col_header, col_bytes \u001b[38;5;241m=\u001b[39m index_to_header_bytes(df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m    181\u001b[0m     ind_header, ind_bytes \u001b[38;5;241m=\u001b[39m index_to_header_bytes(df\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m    182\u001b[0m     headers \u001b[38;5;241m=\u001b[39m [col_header, ind_header]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\partd\\pandas.py:113\u001b[0m, in \u001b[0;36mindex_to_header_bytes\u001b[1;34m(ind)\u001b[0m\n\u001b[0;32m    110\u001b[0m     cat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     values \u001b[38;5;241m=\u001b[39m ind\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 113\u001b[0m header \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mtype\u001b[39m(ind), ind\u001b[38;5;241m.\u001b[39m_get_attributes_dict(), values\u001b[38;5;241m.\u001b[39mdtype, cat)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m pnp\u001b[38;5;241m.\u001b[39mcompress(pnp\u001b[38;5;241m.\u001b[39mserialize(values), values\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m header, \u001b[38;5;28mbytes\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Index' object has no attribute '_get_attributes_dict'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pretrained_data.compute().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e23133bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Index' object has no attribute '_get_attributes_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m<timed eval>:1\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\base.py:310\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    287\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m compute(\u001b[38;5;28mself\u001b[39m, traverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\base.py:595\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    592\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[0;32m    593\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m--> 595\u001b[0m results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[0;32m     87\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[1;32m---> 89\u001b[0m results \u001b[38;5;241m=\u001b[39m get_async(\n\u001b[0;32m     90\u001b[0m     pool\u001b[38;5;241m.\u001b[39msubmit,\n\u001b[0;32m     91\u001b[0m     pool\u001b[38;5;241m.\u001b[39m_max_workers,\n\u001b[0;32m     92\u001b[0m     dsk,\n\u001b[0;32m     93\u001b[0m     keys,\n\u001b[0;32m     94\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m     95\u001b[0m     get_id\u001b[38;5;241m=\u001b[39m_thread_get_id,\n\u001b[0;32m     96\u001b[0m     pack_exception\u001b[38;5;241m=\u001b[39mpack_exception,\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m         _execute_task(task, data)  \u001b[38;5;66;03m# Re-execute locally\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 511\u001b[0m         raise_exception(exc, tb)\n\u001b[0;32m    512\u001b[0m res, worker_id \u001b[38;5;241m=\u001b[39m loads(res_info)\n\u001b[0;32m    513\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m][key] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(exc, tb)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 319\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[1;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     task, data \u001b[38;5;241m=\u001b[39m loads(task_info)\n\u001b[1;32m--> 224\u001b[0m     result \u001b[38;5;241m=\u001b[39m _execute_task(task, data)\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m get_id()\n\u001b[0;32m    226\u001b[0m     result \u001b[38;5;241m=\u001b[39m dumps((result, \u001b[38;5;28mid\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\core.py:121\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    117\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m(_execute_task(a, cache) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args))\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\shuffle.py:945\u001b[0m, in \u001b[0;36mshuffle_group_3\u001b[1;34m(df, col, npartitions, p)\u001b[0m\n\u001b[0;32m    943\u001b[0m g \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(col)\n\u001b[0;32m    944\u001b[0m d \u001b[38;5;241m=\u001b[39m {i: g\u001b[38;5;241m.\u001b[39mget_group(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m g\u001b[38;5;241m.\u001b[39mgroups}\n\u001b[1;32m--> 945\u001b[0m p\u001b[38;5;241m.\u001b[39mappend(d, fsync\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\partd\\encode.py:23\u001b[0m, in \u001b[0;36mEncode.append\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mappend\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 23\u001b[0m     data \u001b[38;5;241m=\u001b[39m valmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode, data)\n\u001b[0;32m     24\u001b[0m     data \u001b[38;5;241m=\u001b[39m valmap(frame, data)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartd\u001b[38;5;241m.\u001b[39mappend(data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\toolz\\dicttoolz.py:85\u001b[0m, in \u001b[0;36mvalmap\u001b[1;34m(func, d, factory)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Apply function to values of dictionary\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m>>> bills = {\"Alice\": [20, 15, 30], \"Bob\": [10, 35]}\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    itemmap\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m rv \u001b[38;5;241m=\u001b[39m factory()\n\u001b[1;32m---> 85\u001b[0m rv\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mzip\u001b[39m(d\u001b[38;5;241m.\u001b[39mkeys(), \u001b[38;5;28mmap\u001b[39m(func, d\u001b[38;5;241m.\u001b[39mvalues())))\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rv\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\partd\\pandas.py:180\u001b[0m, in \u001b[0;36mserialize\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mserialize\u001b[39m(df):\n\u001b[0;32m    176\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Serialize and compress a Pandas DataFrame\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    Uses Pandas blocks, snappy, and blosc to deconstruct an array into bytes\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     col_header, col_bytes \u001b[38;5;241m=\u001b[39m index_to_header_bytes(df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m    181\u001b[0m     ind_header, ind_bytes \u001b[38;5;241m=\u001b[39m index_to_header_bytes(df\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m    182\u001b[0m     headers \u001b[38;5;241m=\u001b[39m [col_header, ind_header]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\partd\\pandas.py:113\u001b[0m, in \u001b[0;36mindex_to_header_bytes\u001b[1;34m(ind)\u001b[0m\n\u001b[0;32m    110\u001b[0m     cat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     values \u001b[38;5;241m=\u001b[39m ind\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 113\u001b[0m header \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mtype\u001b[39m(ind), ind\u001b[38;5;241m.\u001b[39m_get_attributes_dict(), values\u001b[38;5;241m.\u001b[39mdtype, cat)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m pnp\u001b[38;5;241m.\u001b[39mcompress(pnp\u001b[38;5;241m.\u001b[39mserialize(values), values\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m header, \u001b[38;5;28mbytes\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Index' object has no attribute '_get_attributes_dict'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ignoring exception in ensure_cleanup_on_exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\shuffle.py\", line 930, in ensure_cleanup_on_exception\n",
      "    yield\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\shuffle.py\", line 945, in shuffle_group_3\n",
      "    p.append(d, fsync=True)\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\encode.py\", line 23, in append\n",
      "    data = valmap(self.encode, data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\toolz\\dicttoolz.py\", line 85, in valmap\n",
      "    rv.update(zip(d.keys(), map(func, d.values())))\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\pandas.py\", line 180, in serialize\n",
      "    col_header, col_bytes = index_to_header_bytes(df.columns)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\pandas.py\", line 113, in index_to_header_bytes\n",
      "    header = (type(ind), ind._get_attributes_dict(), values.dtype, cat)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Index' object has no attribute '_get_attributes_dict'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\shuffle.py\", line 935, in ensure_cleanup_on_exception\n",
      "    p.drop()\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\encode.py\", line 39, in drop\n",
      "    return self.partd.drop()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\buffer.py\", line 78, in drop\n",
      "    self.slow.drop()\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\partd\\file.py\", line 95, in drop\n",
      "    shutil.rmtree(self.path)\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\shutil.py\", line 759, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\shutil.py\", line 626, in _rmtree_unsafe\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"C:\\Users\\maxim\\anaconda3\\Lib\\shutil.py\", line 624, in _rmtree_unsafe\n",
      "    os.rmdir(path)\n",
      "PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\maxim\\\\AppData\\\\Local\\\\Temp\\\\tmpkfgoewv_.partd'\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pretrained_data.isna().sum().compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
