{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2b387c6",
   "metadata": {},
   "source": [
    "### Validation schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "437116e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear algebra\n",
    "import numpy as np\n",
    "\n",
    "#working with data in table structers\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# working with files\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# to off warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# validation schema \n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a3e721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using ray engine for parallel calculation(for oprimization)\n",
    "%env MODIN_ENGINE=ray\n",
    "import modin.pandas as mpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b039bbbc",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ed819f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data path to sys.path \n",
    "train_test_data_path = \"C:\\\\Repository\\\\DS-Intership-data\\\\train_test_data\\\\\"\n",
    "sys.path.append(train_test_data_path)\n",
    "\n",
    "# initiate dict for data\n",
    "to_read_train_test_data = {}\n",
    "\n",
    "# fill to_read\n",
    "for dir_name, _, files in os.walk(train_test_data_path):\n",
    "    for file in files:\n",
    "        to_read_train_test_data[file] = dir_name + file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "252c8586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample_submission.csv': 'C:\\\\Repository\\\\DS-Intership-data\\\\train_test_data\\\\sample_submission.csv',\n",
       " 'test_data.csv': 'C:\\\\Repository\\\\DS-Intership-data\\\\train_test_data\\\\test_data.csv',\n",
       " 'train_data.csv': 'C:\\\\Repository\\\\DS-Intership-data\\\\train_test_data\\\\train_data.csv'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to_read\n",
    "to_read_train_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaf1415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10.2 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = {}\n",
    "# read data\n",
    "for file, path in to_read_train_test_data.items():\n",
    "    data[file.split('.')[0]] = pd.read_csv(os.path.join(os.path.dirname(path), file), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7181d836",
   "metadata": {},
   "source": [
    "### Validation schema creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f1b6e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    The following indexes will be used:\n",
    "      date_block_num\n",
    "      shop_id\n",
    "      item_category_id\n",
    "      item_id\n",
    "      item_cnt_month\n",
    "      \n",
    "    Concept:\n",
    "    Apply expanding window validation\n",
    "    Monthly predictions\n",
    "\"\"\"\n",
    "\n",
    "class Validation:\n",
    "    def __init__(self, data, metrics=['rmse'], n_splits=10):\n",
    "        self.data = data\n",
    "        self.metrics = metrics\n",
    "        self.n_splits = n_splits\n",
    "\n",
    "        assert set([\n",
    "                    'date_block_num',\n",
    "                    'shop_id',\n",
    "                    'item_category_id',\n",
    "                    'item_id',\n",
    "                    'item_cnt_month'\n",
    "                   ]).issubset(data.columns),\\\n",
    "                \"Invalid data\"\n",
    "        \n",
    "    def calculate_metrics(self, y_pred, y_true):\n",
    "        rmse = mse(y_true, y_pred, squared=True)\n",
    "        return rmse\n",
    "\n",
    "    def evaluate(self, model=RandomForestRegressor(max_depth=5, n_estimators=5, random_state=42)):\n",
    "        eval_report = {}\n",
    "        tscv = TimeSeriesSplit(n_splits=self.n_splits)\n",
    "        data['train_data'] = data['train_data'].dropna()\n",
    "        X = data['train_data'].drop(columns='item_cnt_month')\n",
    "        y = data['train_data'].item_cnt_month\n",
    "        step = 0\n",
    "        for train, test in tscv.split(y):\n",
    "            step += 1\n",
    "\n",
    "            # Split data step\n",
    "            y_tr, y_ts = y.iloc[train].values, y.iloc[test].values\n",
    "            X_tr, X_ts = X.iloc[train].values, X.iloc[test].values\n",
    "\n",
    "            # Train step\n",
    "            rng = np.random.RandomState(42)\n",
    "            model = model\n",
    "            model.fit(X_tr, y_tr)\n",
    "\n",
    "            # Evaluation step\n",
    "            y_tr_pr = model.predict(X_tr)\n",
    "            y_ts_pr = model.predict(X_ts)\n",
    "            \n",
    "            # Metrics\n",
    "            eval_report[\"step\"+str(step)] = {\n",
    "                \"train\\test limits\" : f\"TRAIN: from {train.min()} to  {train.max()}  (size: {train.max() - train.min()} ) \" +\n",
    "                                      f\"TEST: from {test.min()} to  {test.max()}  (size: {test.max() - test.min()} )\",\n",
    "                \"error\" : [self.calculate_metrics(y_tr_pr, y_tr), self.calculate_metrics(y_ts_pr, y_ts)],\n",
    "                \"feature_importance\" : model.feature_importances_,\n",
    "                \"__________________\" : \"_________________________________________________________________________________\"\n",
    "            }\n",
    "        return eval_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b05fb74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8min 37s\n",
      "Wall time: 9min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'step1': {'train\\test limits': 'TRAIN: from 0 to  768538  (size: 768538 ) TEST: from 768539 to  1537070  (size: 768531 )',\n",
       "  'error': [0.8865417115365465, 2.716969283081017],\n",
       "  'feature_importance': array([3.09234013e-03, 0.00000000e+00, 7.68077350e-04, 4.20136059e-03,\n",
       "         1.30872375e-02, 0.00000000e+00, 1.25157869e-03, 2.14183098e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 7.15144810e-04, 8.75384390e-01,\n",
       "         1.04999068e-03, 6.30949907e-02, 2.08190351e-02, 1.03446718e-03,\n",
       "         3.26573926e-03, 1.00938171e-02]),\n",
       "  '__________________': '_________________________________________________________________________________'},\n",
       " 'step2': {'train\\test limits': 'TRAIN: from 0 to  1537070  (size: 1537070 ) TEST: from 1537071 to  2305602  (size: 768531 )',\n",
       "  'error': [1.225768874098291, 1.9906718851848355],\n",
       "  'feature_importance': array([1.70830842e-03, 0.00000000e+00, 3.85108747e-03, 0.00000000e+00,\n",
       "         9.11041125e-03, 0.00000000e+00, 4.88950110e-03, 2.93348027e-04,\n",
       "         1.48426667e-02, 0.00000000e+00, 2.40894011e-03, 5.14246286e-01,\n",
       "         0.00000000e+00, 2.33886268e-01, 1.03767907e-01, 2.10371865e-03,\n",
       "         1.03177723e-01, 5.71383354e-03]),\n",
       "  '__________________': '_________________________________________________________________________________'},\n",
       " 'step3': {'train\\test limits': 'TRAIN: from 0 to  2305602  (size: 2305602 ) TEST: from 2305603 to  3074134  (size: 768531 )',\n",
       "  'error': [1.2427999253917477, 2.4768364804474343],\n",
       "  'feature_importance': array([9.89280569e-03, 0.00000000e+00, 8.69292609e-03, 6.95522829e-04,\n",
       "         5.56309063e-03, 0.00000000e+00, 5.72737071e-04, 2.04465710e-03,\n",
       "         3.29961778e-03, 0.00000000e+00, 0.00000000e+00, 3.46653122e-01,\n",
       "         3.11092356e-04, 4.67473896e-01, 1.29356210e-01, 2.39508331e-02,\n",
       "         1.49348878e-03, 0.00000000e+00]),\n",
       "  '__________________': '_________________________________________________________________________________'},\n",
       " 'step4': {'train\\test limits': 'TRAIN: from 0 to  3074134  (size: 3074134 ) TEST: from 3074135 to  3842666  (size: 768531 )',\n",
       "  'error': [1.3515460669459844, 2.1691925119580735],\n",
       "  'feature_importance': array([1.56166638e-02, 6.56394213e-04, 5.57750963e-03, 1.48223602e-04,\n",
       "         1.37343712e-03, 0.00000000e+00, 0.00000000e+00, 3.88528702e-03,\n",
       "         6.21458089e-03, 6.81822645e-04, 0.00000000e+00, 4.03295870e-01,\n",
       "         1.05898535e-03, 5.17634277e-01, 3.04665204e-02, 6.27557488e-03,\n",
       "         1.27453289e-03, 5.84032069e-03]),\n",
       "  '__________________': '_________________________________________________________________________________'},\n",
       " 'step5': {'train\\test limits': 'TRAIN: from 0 to  3842666  (size: 3842666 ) TEST: from 3842667 to  4611198  (size: 768531 )',\n",
       "  'error': [1.50894245428577, 1.454232945642216],\n",
       "  'feature_importance': array([7.40392204e-03, 1.14493344e-03, 1.01561500e-03, 0.00000000e+00,\n",
       "         4.36696847e-04, 0.00000000e+00, 0.00000000e+00, 3.96278710e-03,\n",
       "         9.53067896e-03, 1.26558328e-03, 0.00000000e+00, 4.08742996e-01,\n",
       "         1.38211036e-03, 5.32796088e-01, 1.94460964e-02, 9.22162623e-03,\n",
       "         3.34135979e-04, 3.31673044e-03]),\n",
       "  '__________________': '_________________________________________________________________________________'},\n",
       " 'step6': {'train\\test limits': 'TRAIN: from 0 to  4611198  (size: 4611198 ) TEST: from 4611199 to  5379730  (size: 768531 )',\n",
       "  'error': [1.472803932263208, 1.3122050523614683],\n",
       "  'feature_importance': array([5.29137301e-03, 0.00000000e+00, 1.26556498e-03, 0.00000000e+00,\n",
       "         1.78248276e-03, 0.00000000e+00, 1.65012707e-04, 1.23264323e-06,\n",
       "         7.37479457e-03, 8.20315390e-04, 0.00000000e+00, 4.07357521e-01,\n",
       "         5.06405241e-03, 5.51563870e-01, 1.38591612e-02, 4.71645631e-03,\n",
       "         1.62538643e-04, 5.75624503e-04]),\n",
       "  '__________________': '_________________________________________________________________________________'},\n",
       " 'step7': {'train\\test limits': 'TRAIN: from 0 to  5379730  (size: 5379730 ) TEST: from 5379731 to  6148262  (size: 768531 )',\n",
       "  'error': [1.4278310475390645, 2.145299760408405],\n",
       "  'feature_importance': array([6.60248483e-03, 1.76693222e-04, 2.26059267e-04, 0.00000000e+00,\n",
       "         2.03655726e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         1.22721179e-03, 0.00000000e+00, 0.00000000e+00, 5.73717370e-01,\n",
       "         4.28271878e-04, 3.58283900e-01, 3.90639195e-02, 1.38390205e-03,\n",
       "         1.23625518e-02, 4.49107813e-03]),\n",
       "  '__________________': '_________________________________________________________________________________'},\n",
       " 'step8': {'train\\test limits': 'TRAIN: from 0 to  6148262  (size: 6148262 ) TEST: from 6148263 to  6916794  (size: 768531 )',\n",
       "  'error': [1.4592980190290872, 2.561711971687206],\n",
       "  'feature_importance': array([2.24818205e-03, 1.67457675e-04, 1.18792996e-03, 4.30170944e-04,\n",
       "         5.61630599e-04, 0.00000000e+00, 0.00000000e+00, 5.23482654e-04,\n",
       "         1.83268131e-03, 0.00000000e+00, 5.36336311e-04, 6.85573780e-01,\n",
       "         1.10030020e-03, 2.68726451e-01, 1.22954145e-02, 2.07874278e-03,\n",
       "         1.97234190e-02, 3.01402206e-03]),\n",
       "  '__________________': '_________________________________________________________________________________'},\n",
       " 'step9': {'train\\test limits': 'TRAIN: from 0 to  6916794  (size: 6916794 ) TEST: from 6916795 to  7685326  (size: 768531 )',\n",
       "  'error': [1.5754681176812528, 2.114214138781148],\n",
       "  'feature_importance': array([4.05395860e-03, 2.69138893e-04, 1.84147574e-03, 8.36953544e-05,\n",
       "         3.03220904e-04, 1.67670505e-04, 5.90331366e-04, 1.98288592e-04,\n",
       "         2.80000065e-04, 9.97644882e-05, 0.00000000e+00, 8.76261601e-01,\n",
       "         1.15924502e-03, 6.00891465e-02, 7.49313921e-03, 2.70526180e-04,\n",
       "         4.28475148e-02, 3.99128226e-03]),\n",
       "  '__________________': '_________________________________________________________________________________'},\n",
       " 'step10': {'train\\test limits': 'TRAIN: from 0 to  7685326  (size: 7685326 ) TEST: from 7685327 to  8453858  (size: 768531 )',\n",
       "  'error': [1.603128894428497, 1.5068718068178784],\n",
       "  'feature_importance': array([3.51684681e-03, 8.39769627e-04, 3.12565940e-04, 0.00000000e+00,\n",
       "         9.14758050e-03, 2.36072278e-04, 1.00134649e-04, 1.88194967e-04,\n",
       "         3.36451673e-04, 7.35553320e-04, 4.49128887e-04, 8.87536744e-01,\n",
       "         2.56499634e-03, 2.43889290e-02, 5.76224151e-03, 4.12818825e-04,\n",
       "         6.06703971e-02, 2.80157483e-03]),\n",
       "  '__________________': '_________________________________________________________________________________'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "val = Validation(data['train_data'])\n",
    "val.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
