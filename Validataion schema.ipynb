{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2b387c6",
   "metadata": {},
   "source": [
    "### Validation schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "437116e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear algebra\n",
    "import numpy as np\n",
    "\n",
    "#working with data in table structers\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# working with files\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# to off warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# validation schema \n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a3e721b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODIN_ENGINE=ray\n"
     ]
    }
   ],
   "source": [
    "# using ray engine for parallel calculation(for oprimization)\n",
    "%env MODIN_ENGINE=ray\n",
    "import modin.pandas as mpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b039bbbc",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ed819f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add data path to sys.path \n",
    "train_test_data_path = \"C:\\\\Repository\\\\DS-Intership-data\\\\train_test_data\\\\\"\n",
    "sys.path.append(train_test_data_path)\n",
    "\n",
    "# initiate dict for data\n",
    "to_read_train_test_data = {}\n",
    "\n",
    "# fill to_read\n",
    "for dir_name, _, files in os.walk(train_test_data_path):\n",
    "    for file in files:\n",
    "        to_read_train_test_data[file] = dir_name + file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "252c8586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample_submission.csv': 'C:\\\\Repository\\\\DS-Intership-data\\\\train_test_data\\\\sample_submission.csv',\n",
       " 'test_data.csv': 'C:\\\\Repository\\\\DS-Intership-data\\\\train_test_data\\\\test_data.csv',\n",
       " 'train_data.csv': 'C:\\\\Repository\\\\DS-Intership-data\\\\train_test_data\\\\train_data.csv'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to_read\n",
    "to_read_train_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaf1415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10.1 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = {}\n",
    "# read data\n",
    "for file, path in to_read_train_test_data.items():\n",
    "    data[file.split('.')[0]] = pd.read_csv(os.path.join(os.path.dirname(path), file), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7181d836",
   "metadata": {},
   "source": [
    "### Validation schema creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8f1b6e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    The following indexes will be used:\n",
    "      date_block_num\n",
    "      shop_id\n",
    "      item_category_id\n",
    "      item_id\n",
    "      item_cnt_month\n",
    "      \n",
    "    Concept:\n",
    "    Apply expanding window validation (except last month - target of competition)\n",
    "    Monthly predictions\n",
    "\"\"\"\n",
    "\n",
    "class Validation:\n",
    "    def __init__(self, train_data,\n",
    "                 test_data, metrics=['rmse'],\n",
    "                 n_splits=2,\n",
    "                 model=DecisionTreeRegressor(max_depth=1, random_state=42)\n",
    "                ):\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.metrics = metrics\n",
    "        self.n_splits = n_splits\n",
    "        self.model = model\n",
    "\n",
    "        # Check data for valid columns\n",
    "        assert set([\n",
    "                    'date_block_num',\n",
    "                    'shop_id',\n",
    "                    'item_category_id',\n",
    "                    'item_id',\n",
    "                    'item_cnt_month'\n",
    "                   ]).issubset(train_data.columns),\\\n",
    "                \"Invalid data\"\n",
    "        \n",
    "        assert set([\n",
    "                    'shop_id',\n",
    "                    'item_id',\n",
    "                    'ID'\n",
    "                    ]).issubset(test_data.columns),\\\n",
    "                \"Invalid data\"\n",
    "        \n",
    "        # Check for valid variables\n",
    "        assert train_data.isna().sum().sum() == 0, 'Data have NaNs'\n",
    "        assert np.isfinite(train_data).sum().sum() != 0, 'Data have Infs'\n",
    "        \n",
    "        self.X = train_data.drop(columns='item_cnt_month')\n",
    "        self.y = train_data[['item_id', 'shop_id', 'item_cnt_month']]\n",
    "        \n",
    "        \n",
    "    def calculate_metrics(self, y_pred, y_true):\n",
    "        rmse = mse(y_true, y_pred, squared=True)\n",
    "        return rmse\n",
    "    \n",
    "    # Predict sales for November 2015\n",
    "    def fit_predict(self, predictions_by_ID = True):\n",
    "        pass\n",
    "\n",
    "    def evaluate(self, predictions_by_ID = True):\n",
    "        eval_report = {}\n",
    "        tscv = TimeSeriesSplit(n_splits=self.n_splits)\n",
    "        step = 0\n",
    "        for train, test in tscv.split(self.y):\n",
    "            step += 1\n",
    "\n",
    "            # Split data step\n",
    "            y_tr, y_ts = self.y.iloc[train], self.y.iloc[test]\n",
    "            X_tr, X_ts = self.X.iloc[train], self.X.iloc[test]\n",
    "\n",
    "            # Train step\n",
    "            rng = np.random.RandomState(42)\n",
    "            model = self.model\n",
    "            model.fit(X_tr.values, y_tr.item_cnt_month.values)\n",
    "\n",
    "            # Evaluation step\n",
    "            y_tr_pr = pd.DataFrame(index=X_tr.index, data=model.predict(X_tr.values), columns=['item_cnt_month'])\n",
    "            y_ts_pr = pd.DataFrame(index=X_ts.index, data=model.predict(X_ts.values), columns=['item_cnt_month'])\n",
    "            \n",
    "            # Extract step (predictions by ID)\n",
    "            if predictions_by_ID == True:\n",
    "                nan_report = {}\n",
    "                y_tr = y_tr.merge(self.test_data, on=['shop_id', 'item_id'], how='right')\n",
    "                nan_report['y_train'] = f\"{y_tr.item_cnt_month.isna().sum() / y_tr.shape[0] * 100} %\"\n",
    "                y_tr = y_tr.fillna(0)\n",
    "                y_ts = y_ts.merge(self.test_data, on=['shop_id', 'item_id'], how='right')\n",
    "                nan_report['y_test'] = f\"{y_ts.item_cnt_month.isna().sum() / y_ts.shape[0] * 100} %\"\n",
    "                y_ts = y_ts.fillna(0)\n",
    "                y_tr_pr = X_tr.join(y_tr_pr)[['item_id', 'shop_id', 'item_cnt_month']].\\\n",
    "                                            merge(self.test_data, on=['shop_id', 'item_id'], how='right')\n",
    "                nan_report['y_train_pred'] = f\"{y_tr_pr.item_cnt_month.isna().sum() / y_tr_pr.shape[0] * 100} %\"\n",
    "                y_tr_pr = y_tr_pr.fillna(0)\n",
    "                y_ts_pr = X_ts.join(y_ts_pr)[['item_id', 'shop_id', 'item_cnt_month']].\\\n",
    "                                            merge(self.test_data, on=['shop_id', 'item_id'], how='right')\n",
    "                nan_report['y_test_pred'] = f\"{y_ts_pr.item_cnt_month.isna().sum() / y_ts_pr.shape[0] * 100} %\"\n",
    "                y_ts_pr = y_ts_pr.fillna(0)\n",
    "            \n",
    "            # Metrics calucaltion step\n",
    "            eval_report[\"step\"+str(step)] = {\n",
    "                \"train\\test limits\" : f\"TRAIN: from {train.min()} to  {train.max()}  (size: {train.max() - train.min()} ) \" +\n",
    "                                      f\"TEST: from {test.min()} to  {test.max()}  (size: {test.max() - test.min()} )\",\n",
    "                \"error\" : [self.calculate_metrics(y_tr_pr.item_cnt_month, y_tr.item_cnt_month),\n",
    "                           self.calculate_metrics(y_ts_pr.item_cnt_month, y_ts.item_cnt_month)],\n",
    "                \"feature_importance\" : model.feature_importances_,\n",
    "                \"nan_report\" : nan_report,\n",
    "                \"__________________\" : \"_________________________________________________________________________________\"\n",
    "            }\n",
    "            \n",
    "        return eval_report, y_ts_pr       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b05fb74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 562 ms\n",
      "Wall time: 567 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val = Validation(train_data=data['train_data'],\n",
    "                 test_data=data['test_data'],\n",
    "                 n_splits=5,\n",
    "                 model = DecisionTreeRegressor(max_depth=1, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "256e7524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 25.8 s\n",
      "Wall time: 26.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'step1': {'train\\test limits': 'TRAIN: from 0 to  1408978  (size: 1408978 ) TEST: from 1408979 to  2817954  (size: 1408975 )',\n",
       "   'error': [3.958650855160097, 13.684399963683227],\n",
       "   'feature_importance': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "          0.]),\n",
       "   'nan_report': {'y_train': '52.728930571837964 %',\n",
       "    'y_test': '46.75204073568098 %',\n",
       "    'y_train_pred': '52.728930571837964 %',\n",
       "    'y_test_pred': '46.75204073568098 %'},\n",
       "   '__________________': '_________________________________________________________________________________'},\n",
       "  'step2': {'train\\test limits': 'TRAIN: from 0 to  2817954  (size: 2817954 ) TEST: from 2817955 to  4226930  (size: 1408975 )',\n",
       "   'error': [7.500121799609886, 7.089370749074403],\n",
       "   'feature_importance': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0.]),\n",
       "   'nan_report': {'y_train': '32.206109978031144 %',\n",
       "    'y_test': '36.75200293560027 %',\n",
       "    'y_train_pred': '32.206109978031144 %',\n",
       "    'y_test_pred': '36.75200293560027 %'},\n",
       "   '__________________': '_________________________________________________________________________________'},\n",
       "  'step3': {'train\\test limits': 'TRAIN: from 0 to  4226930  (size: 4226930 ) TEST: from 4226931 to  5635906  (size: 1408975 )',\n",
       "   'error': [8.926791746336765, 6.993593527749241],\n",
       "   'feature_importance': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0.]),\n",
       "   'nan_report': {'y_train': '19.60814102871642 %',\n",
       "    'y_test': '26.158442697339574 %',\n",
       "    'y_train_pred': '19.60814102871642 %',\n",
       "    'y_test_pred': '26.158442697339574 %'},\n",
       "   '__________________': '_________________________________________________________________________________'},\n",
       "  'step4': {'train\\test limits': 'TRAIN: from 0 to  5635906  (size: 5635906 ) TEST: from 5635907 to  7044882  (size: 1408975 )',\n",
       "   'error': [9.256846361695366, 7.112607894096999],\n",
       "   'feature_importance': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0.]),\n",
       "   'nan_report': {'y_train': '11.220524762464464 %',\n",
       "    'y_test': '14.948257483090527 %',\n",
       "    'y_train_pred': '11.220524762464464 %',\n",
       "    'y_test_pred': '14.948257483090527 %'},\n",
       "   '__________________': '_________________________________________________________________________________'},\n",
       "  'step5': {'train\\test limits': 'TRAIN: from 0 to  7044882  (size: 7044882 ) TEST: from 7044883 to  8453858  (size: 1408975 )',\n",
       "   'error': [8.420716134135137, 4.581903614157665],\n",
       "   'feature_importance': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "          0.]),\n",
       "   'nan_report': {'y_train': '5.3886855880878715 %',\n",
       "    'y_test': '5.231937396046579 %',\n",
       "    'y_train_pred': '5.3886855880878715 %',\n",
       "    'y_test_pred': '5.231937396046579 %'},\n",
       "   '__________________': '_________________________________________________________________________________'}},\n",
       "         item_id  shop_id  item_cnt_month      ID\n",
       " 0          5037        5            0.33       0\n",
       " 1          5037        5            0.33       0\n",
       " 2          5037        5            0.33       0\n",
       " 3          5037        5            0.33       0\n",
       " 4          5037        5            0.33       0\n",
       " ...         ...      ...             ...     ...\n",
       " 963768      969       45            0.33  214199\n",
       " 963769      969       45            0.33  214199\n",
       " 963770      969       45            0.33  214199\n",
       " 963771      969       45            0.33  214199\n",
       " 963772      969       45            0.33  214199\n",
       " \n",
       " [963773 rows x 4 columns])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "val.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
